{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishanisingh/ML-Notes-in-Markdown/blob/master/english_to_spanish_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vutuS3_6xZ1"
      },
      "source": [
        "# English to Spanish translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7_KQBRJ6xZ5"
      },
      "source": [
        "## Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEXTjVe96xZ5"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5zihZFC6xZ6"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hxNMA7F6xZ6",
        "outputId": "783fbed6-6340-44f0-c164-bdbea5d01105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2638744/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "dataset = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "dataset = pathlib.Path(dataset).parent / \"spa-eng\" / \"spa.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAJKlzhK6xZ6"
      },
      "source": [
        "## Convert the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krI4BzHb6xZ7"
      },
      "outputs": [],
      "source": [
        "with open(dataset) as f:\n",
        "    sentences = f.read().split(\"\\n\")[:-1]\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    english, spanish = sentence.split(\"\\t\")\n",
        "    spanish = \"[start] \" + spanish + \" [end]\"\n",
        "    data.append((english, spanish))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCtGWGXm6xZ8",
        "outputId": "3caea59f-bb4c-40c8-d4f5-babb35901c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('People speak so much about the need for leaving a better planet for our children, and forget the urgency of leaving better children for our planet.', '[start] La gente habla tanto de que necesitan dejar un mejor planeta para nuestros hijos, y se olvidan de la urgencia de dejar mejores niños para nuestro planeta. [end]')\n",
            "('Nobody knows the truth.', '[start] Nadie sabe la verdad. [end]')\n",
            "('Do you want to talk?', '[start] ¿Querés hablar? [end]')\n",
            "(\"No one's working.\", '[start] Nadie está trabajando. [end]')\n",
            "('I heard an unusual sound.', '[start] Oí un ruido extraño. [end]')\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(random.choice(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcbXnEhS6xZ8",
        "outputId": "a10cb8da-b51c-4db5-a6b1-ebb25fa9d223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(data)\n",
        "pairs = int(0.15 * len(data))\n",
        "sampling = len(data) - 2 * pairs\n",
        "training = data[:sampling]\n",
        "validation = data[sampling : sampling + pairs]\n",
        "testing = data[sampling + pairs :]\n",
        "\n",
        "print(f\"{len(data)} total pairs\")\n",
        "print(f\"{len(training)} training pairs\")\n",
        "print(f\"{len(validation)} validation pairs\")\n",
        "print(f\"{len(testing)} test pairs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxG5IhrK6xZ8"
      },
      "outputs": [],
      "source": [
        "character = string.punctuation + \"¿\"\n",
        "character = character.replace(\"[\", \"\")\n",
        "character = character.replace(\"]\", \"\")\n",
        "\n",
        "vocabulary = 15000\n",
        "size = 20\n",
        "num_samples = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    letter = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(letter, \"[%s]\" % re.escape(character), \"\")\n",
        "\n",
        "\n",
        "english_vectorization = TextVectorization(\n",
        "    max_tokens=vocabulary, output_mode=\"int\", output_sequence_length=size,\n",
        ")\n",
        "spanish_vectorization = TextVectorization(\n",
        "    max_tokens=vocabulary,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=size + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "english_sentences = [pair[0] for pair in training]\n",
        "spanish_sentences = [pair[1] for pair in training]\n",
        "english_vectorization.adapt(english_sentences)\n",
        "spanish_vectorization.adapt(spanish_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Aht7t5a6xZ9"
      },
      "outputs": [],
      "source": [
        "def format_dataset(english, spanish):\n",
        "    english = english_vectorization(english)\n",
        "    spanish = spanish_vectorization(spanish)\n",
        "    return ({\"encoder_inputs\": english, \"decoder_inputs\": spanish[:, :-1],}, spanish[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    english_texts, spanish_texts = zip(*pairs)\n",
        "    english_texts = list(english_texts)\n",
        "    spanish_texts = list(spanish_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((english_texts, spanish_texts))\n",
        "    dataset = dataset.batch(num_samples)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "training_dataset = make_dataset(training)\n",
        "validation_dataset = make_dataset(validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pefabi_M6xZ9",
        "outputId": "25824205-c1c0-44c2-9411-4172b1ffd2fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source[\"encoder_inputs\"].shape: (64, 20)\n",
            "source[\"decoder_inputs\"].shape: (64, 20)\n",
            "destination.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for source, destination in training_dataset.take(1):\n",
        "    print(f'source[\"encoder_inputs\"].shape: {source[\"encoder_inputs\"].shape}')\n",
        "    print(f'source[\"decoder_inputs\"].shape: {source[\"decoder_inputs\"].shape}')\n",
        "    print(f\"destination.shape: {destination.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8IoibgZ6xZ9"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HlA6N8Y6xZ9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.types.core import Value\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embedding_dimension, dimensionality, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.dimensionality = dimensionality\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embedding_dimension\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dimensionality, activation=\"relu\"), layers.Dense(embedding_dimension),]\n",
        "        )\n",
        "        self.normalization1 = layers.LayerNormalization()\n",
        "        self.normalization2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, source, mask=None):\n",
        "        if mask is not None:\n",
        "            attention_scores = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=source, value=source, key=source, attention_mask=attention_scores\n",
        "        )\n",
        "        proj_input = self.normalization1(source + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.normalization2(proj_input + proj_output)\n",
        "    def get_config(self):\n",
        "        parameter = super().get_config()\n",
        "        parameter.update({\n",
        "            \"embedding_dimension\": self.embedding_dimension,\n",
        "            \"dimensionality\": self.dimensionality,\n",
        "            \"num_heads\": self.num_heads,\n",
        "        })\n",
        "        return parameter\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, size, vocabulary, embedding_dimension, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocabulary, output_dim=embedding_dimension\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=size, output_dim=embedding_dimension\n",
        "        )\n",
        "        self.size = size\n",
        "        self.vocabulary = vocabulary\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "\n",
        "    def call(self, source):\n",
        "        value = tf.shape(source)[-1]\n",
        "        positions = tf.range(start=0, limit=value, delta=1)\n",
        "        units_embeddings = self.token_embeddings(source)\n",
        "        order_embeddings = self.position_embeddings(positions)\n",
        "        return units_embeddings + order_embeddings\n",
        "\n",
        "    def compute_mask(self, source, mask=None):\n",
        "        return tf.math.not_equal(source, 0)\n",
        "    def get_config(self):\n",
        "        parameter = super().get_config()\n",
        "        parameter.update({\n",
        "            \"size\": self.size,\n",
        "            \"vocabulary\": self.vocabulary,\n",
        "            \"embedding_dimension\": self.embedding_dimension,\n",
        "        })\n",
        "        return parameter\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embedding_dimension, internal_dimension, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.internal_dimension = internal_dimension\n",
        "        self.num_heads = num_heads\n",
        "        self.multihead_attention1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embedding_dimension\n",
        "        )\n",
        "        self.multihead_attention2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embedding_dimension\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(internal_dimension, activation=\"relu\"), layers.Dense(embedding_dimension),]\n",
        "        )\n",
        "        self.normalization1 = layers.LayerNormalization()\n",
        "        self.normalization2 = layers.LayerNormalization()\n",
        "        self.normalization3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, source, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(source)\n",
        "        if mask is not None:\n",
        "            attention_scores = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            attention_scores = tf.minimum(attention_scores, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.multihead_attention1(\n",
        "            query=source, value=source, key=source, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.normalization1(source + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.multihead_attention2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=attention_scores,\n",
        "        )\n",
        "        out_2 = self.normalization2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.normalization3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, source):\n",
        "        input_shape = tf.shape(source)\n",
        "        num_samples, size = input_shape[0], input_shape[1]\n",
        "        i = tf.range(size)[:, tf.newaxis]\n",
        "        j = tf.range(size)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(num_samples, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "    def get_config(self):\n",
        "        parameter = super().get_config()\n",
        "        parameter.update({\n",
        "            \"embedding_dimension\": self.embedding_dimension,\n",
        "            \"internal_dimension\": self.internal_dimension,\n",
        "            \"num_heads\": self.num_heads,\n",
        "        })\n",
        "        return parameter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPijbtVp6xZ-"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 256\n",
        "internal_dimension = 2048\n",
        "num_heads = 8\n",
        "\n",
        "source_encoder = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "sample = PositionalEmbedding(size, vocabulary, embedding_dimension)(source_encoder)\n",
        "destination_encoder = TransformerEncoder(embedding_dimension, internal_dimension, num_heads)(sample)\n",
        "encoder = keras.Model(source_encoder, destination_encoder)\n",
        "\n",
        "source_decoder = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "source_sequence = keras.Input(shape=(None, embedding_dimension), name=\"decoder_state_inputs\")\n",
        "sample = PositionalEmbedding(size, vocabulary, embedding_dimension)(source_decoder)\n",
        "sample = TransformerDecoder(embedding_dimension, internal_dimension, num_heads)(sample, source_sequence)\n",
        "sample = layers.Dropout(0.5)(sample)\n",
        "destination_decoder = layers.Dense(vocabulary, activation=\"softmax\")(sample)\n",
        "decoder = keras.Model([source_decoder, source_sequence], destination_decoder)\n",
        "\n",
        "destination_decoder = decoder([source_decoder, destination_encoder])\n",
        "transformer = keras.Model(\n",
        "    [source_encoder, source_decoder], destination_decoder, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbxPuc5Q6xZ-"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtKSXzu-6xZ-",
        "outputId": "375bbb67-aa1c-4d9c-b63f-29313a7ce0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " positional_embedding (Posi  (None, None, 256)            3845120   ['encoder_inputs[0][0]']      \n",
            " tionalEmbedding)                                                                                 \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " transformer_encoder (Trans  (None, None, 256)            3155456   ['positional_embedding[0][0]']\n",
            " formerEncoder)                                                                                   \n",
            "                                                                                                  \n",
            " model_1 (Functional)        (None, None, 15000)          1295964   ['decoder_inputs[0][0]',      \n",
            "                                                          0          'transformer_encoder[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19960216 (76.14 MB)\n",
            "Trainable params: 19960216 (76.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "1302/1302 [==============================] - 105s 73ms/step - loss: 3.8248 - accuracy: 0.4364 - val_loss: 2.8761 - val_accuracy: 0.5421\n",
            "Epoch 2/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 2.8649 - accuracy: 0.5475 - val_loss: 2.5170 - val_accuracy: 0.5914\n",
            "Epoch 3/30\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 2.5589 - accuracy: 0.5924 - val_loss: 2.3749 - val_accuracy: 0.6137\n",
            "Epoch 4/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 2.3943 - accuracy: 0.6188 - val_loss: 2.3286 - val_accuracy: 0.6237\n",
            "Epoch 5/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 2.2875 - accuracy: 0.6377 - val_loss: 2.2961 - val_accuracy: 0.6318\n",
            "Epoch 6/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 2.2104 - accuracy: 0.6516 - val_loss: 2.3150 - val_accuracy: 0.6315\n",
            "Epoch 7/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 2.1457 - accuracy: 0.6648 - val_loss: 2.2639 - val_accuracy: 0.6444\n",
            "Epoch 8/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 2.0806 - accuracy: 0.6767 - val_loss: 2.2342 - val_accuracy: 0.6535\n",
            "Epoch 9/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 2.0316 - accuracy: 0.6871 - val_loss: 2.2131 - val_accuracy: 0.6569\n",
            "Epoch 10/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.9827 - accuracy: 0.6956 - val_loss: 2.2083 - val_accuracy: 0.6609\n",
            "Epoch 11/30\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.9447 - accuracy: 0.7028 - val_loss: 2.2302 - val_accuracy: 0.6621\n",
            "Epoch 12/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.9138 - accuracy: 0.7076 - val_loss: 2.2449 - val_accuracy: 0.6586\n",
            "Epoch 13/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8850 - accuracy: 0.7134 - val_loss: 2.2576 - val_accuracy: 0.6615\n",
            "Epoch 14/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8614 - accuracy: 0.7178 - val_loss: 2.2929 - val_accuracy: 0.6601\n",
            "Epoch 15/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8398 - accuracy: 0.7217 - val_loss: 2.2467 - val_accuracy: 0.6667\n",
            "Epoch 16/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8168 - accuracy: 0.7265 - val_loss: 2.2812 - val_accuracy: 0.6627\n",
            "Epoch 17/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.8003 - accuracy: 0.7293 - val_loss: 2.2694 - val_accuracy: 0.6649\n",
            "Epoch 18/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.7834 - accuracy: 0.7321 - val_loss: 2.2769 - val_accuracy: 0.6682\n",
            "Epoch 19/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.7654 - accuracy: 0.7359 - val_loss: 2.2977 - val_accuracy: 0.6695\n",
            "Epoch 20/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.7452 - accuracy: 0.7390 - val_loss: 2.3123 - val_accuracy: 0.6660\n",
            "Epoch 21/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.7347 - accuracy: 0.7412 - val_loss: 2.3056 - val_accuracy: 0.6683\n",
            "Epoch 22/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.7223 - accuracy: 0.7432 - val_loss: 2.3154 - val_accuracy: 0.6704\n",
            "Epoch 23/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.7047 - accuracy: 0.7461 - val_loss: 2.3379 - val_accuracy: 0.6671\n",
            "Epoch 24/30\n",
            "1302/1302 [==============================] - 88s 68ms/step - loss: 1.6898 - accuracy: 0.7492 - val_loss: 2.3439 - val_accuracy: 0.6712\n",
            "Epoch 25/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6771 - accuracy: 0.7516 - val_loss: 2.3752 - val_accuracy: 0.6677\n",
            "Epoch 26/30\n",
            "1302/1302 [==============================] - 90s 69ms/step - loss: 1.6672 - accuracy: 0.7528 - val_loss: 2.3702 - val_accuracy: 0.6715\n",
            "Epoch 27/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6569 - accuracy: 0.7549 - val_loss: 2.3767 - val_accuracy: 0.6688\n",
            "Epoch 28/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6405 - accuracy: 0.7576 - val_loss: 2.3730 - val_accuracy: 0.6711\n",
            "Epoch 29/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6348 - accuracy: 0.7588 - val_loss: 2.3838 - val_accuracy: 0.6750\n",
            "Epoch 30/30\n",
            "1302/1302 [==============================] - 89s 68ms/step - loss: 1.6211 - accuracy: 0.7614 - val_loss: 2.4053 - val_accuracy: 0.6714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a557c4202e0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Commenting since TRAINING IS COMPLETE\n",
        "#epochs = 30\n",
        "\n",
        "#transformer.summary()\n",
        "#transformer.compile(\n",
        "#    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "#)\n",
        "#transformer.fit(training_dataset, epochs=epochs, validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "SZ8l1F-s-Yu1"
      },
      "outputs": [],
      "source": [
        "# prompt: save transformer\n",
        "# SAVED AFTER FIRST SUCCESSFULL execution\n",
        "\n",
        "#transformer.save_weights('./checkpoints/my_checkpoint')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.load_weights(\"./checkpoints/my_checkpoint\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H35EuFaMXUil",
        "outputId": "28eaf58f-2b69-4bec-f797-dc5a81b2a283"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7a5503b11480>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N_V9jYw6xZ-"
      },
      "source": [
        "## Decode the sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK5MMEP06xZ-",
        "outputId": "74daa3fa-969a-4616-e8c7-c8abac20f013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English:  I don't want to take risks.\n",
            "Espanol:  [start] no quiero llevar todos los nombres [end]\n",
            "English:  He was an Olympic champion in weightlifting.\n",
            "Espanol:  [start] Él era un [UNK] [UNK] [end]\n",
            "English:  I know what's at stake.\n",
            "Espanol:  [start] sé lo que está en juego [end]\n",
            "English:  What time did you get here this morning?\n",
            "Espanol:  [start] a qué hora te has llegado esta mañana [end]\n",
            "English:  Tom still has some time.\n",
            "Espanol:  [start] tom todavía tiene un poco de tiempo [end]\n",
            "English:  I think otherwise.\n",
            "Espanol:  [start] creo lo mismo de una forma [end]\n",
            "English:  I'm angry about what happened, too.\n",
            "Espanol:  [start] también estoy enojado por lo que había dicho [end]\n",
            "English:  The shop is just in front of the station.\n",
            "Espanol:  [start] la tienda está justo al frente de la estación [end]\n",
            "English:  Tom was impatient to see Mary again.\n",
            "Espanol:  [start] tom está impaciente por ver a mary de nuevo [end]\n",
            "English:  She was kind enough to accompany me to the station.\n",
            "Espanol:  [start] ella era tan amable como para [UNK] a la estación [end]\n",
            "English:  Tom died of old age.\n",
            "Espanol:  [start] tom murió de edad [end]\n",
            "English:  We must clean up the kitchen.\n",
            "Espanol:  [start] tenemos que limpiar la cocina [end]\n",
            "English:  This looks good.\n",
            "Espanol:  [start] esto se ve bien [end]\n",
            "English:  You can go.\n",
            "Espanol:  [start] tú puedes ir [end]\n",
            "English:  Where is the toilet?\n",
            "Espanol:  [start] dónde está la prueba [end]\n",
            "English:  I know the rules.\n",
            "Espanol:  [start] yo conozco las reglas [end]\n",
            "English:  Don't read too much into this.\n",
            "Espanol:  [start] no lo [UNK] [end]\n",
            "English:  I've heard of him, but I don't know him personally.\n",
            "Espanol:  [start] lo he oído pero no me lo conozco en persona [end]\n",
            "English:  He was in time for the appointment.\n",
            "Espanol:  [start] Él estaba a hora en la cita [end]\n",
            "English:  You don't look the same.\n",
            "Espanol:  [start] no te ves mismo [end]\n",
            "English:  Sit still.\n",
            "Espanol:  [start] quédate [end]\n",
            "English:  In fact, he loves her.\n",
            "Espanol:  [start] de hecho él la ama [end]\n",
            "English:  You know I hate meetings.\n",
            "Espanol:  [start] tú sabes bailar [end]\n",
            "English:  I am very curious.\n",
            "Espanol:  [start] soy muy [UNK] [end]\n",
            "English:  Tom always had a back up plan.\n",
            "Espanol:  [start] tom siempre tenía más de vuelta [end]\n",
            "English:  They found it.\n",
            "Espanol:  [start] lo ellos lo encontraron [end]\n",
            "English:  That boy is really shy.\n",
            "Espanol:  [start] ese chico es muy tímido [end]\n",
            "English:  She couldn't convince him to ask for a loan.\n",
            "Espanol:  [start] ella no pudo convencer para que le [UNK] un [UNK] [end]\n",
            "English:  I don't think that was a wise decision.\n",
            "Espanol:  [start] no creo que la pregunta fue una decisión [end]\n",
            "English:  Oh, no! We're running out of gas.\n",
            "Espanol:  [start] mira no [UNK] a la oportunidad [end]\n"
          ]
        }
      ],
      "source": [
        "spanish_vocabulary = spanish_vectorization.get_vocabulary()\n",
        "spanish_index = dict(zip(range(len(spanish_vocabulary)), spanish_vocabulary))\n",
        "decoded_size = 20\n",
        "\n",
        "\n",
        "def decode(original_sentence):\n",
        "    source_units = english_vectorization([original_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(decoded_size):\n",
        "        destination_units = spanish_vectorization([decoded_sentence])[:, :-1]\n",
        "        transform = transformer([source_units, destination_units])\n",
        "\n",
        "        index_unit = np.argmax(transform[0, i, :])\n",
        "        sampled_unit = spanish_index[index_unit]\n",
        "        decoded_sentence += \" \" + sampled_unit\n",
        "\n",
        "        if sampled_unit == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "english_testing = [pair[0] for pair in testing]\n",
        "for _ in range(30):\n",
        "    original_sentence = random.choice(english_testing)\n",
        "    print(\"English: \",original_sentence)\n",
        "    translated_sentence = decode(original_sentence)\n",
        "    print(\"Espanol: \",translated_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZbPlZoodC82"
      },
      "source": [
        "## Translating a specific sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dRtr7aAIPla",
        "outputId": "a2636dad-83f8-4dec-a954-b5b462336e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English:  This will help you\n",
            "Espanol:  [start] esto te va a ayudar [end]\n"
          ]
        }
      ],
      "source": [
        "original_sentence = \"This will help you\"\n",
        "print(\"English: \",original_sentence)\n",
        "translated_sentence = decode(original_sentence)\n",
        "print(\"Espanol: \",translated_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Chrome Audo and speech to text"
      ],
      "metadata": {
        "id": "Ksu4c0RTlGPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install ffmpeg-python\n",
        "!pip install huggingsound\n",
        "!pip install pydub\n",
        "\n",
        "model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\")"
      ],
      "metadata": {
        "id": "n_24iB6LlEa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "import pydub\n",
        "from huggingsound import SpeechRecognitionModel\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "\n",
        "def write(f, sr, x, normalized=False):\n",
        "    \"\"\"numpy array to MP3\"\"\"\n",
        "    channels = 2 if (x.ndim == 2 and x.shape[1] == 2) else 1\n",
        "    if normalized:  # normalized array - each item should be a float in [-1, 1)\n",
        "        y = np.int16(x * 2 ** 15)\n",
        "    else:\n",
        "        y = np.int16(x)\n",
        "    song = pydub.AudioSegment(y.tobytes(), frame_rate=sr, sample_width=2, channels=channels)\n",
        "    song.export(f, format=\"mp3\", bitrate=\"320k\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jkizW-xEe2MI"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "audio, sr = get_audio()\n",
        "write('out2.mp3', sr, audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "id": "YLMcQ-MYiFlT",
        "outputId": "116e36b1-5d4f-4496-8da6-742c662e40b4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };\n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_paths = ['/content/out2.mp3']\n",
        "\n",
        "transcriptions = model.transcribe(audio_paths)\n",
        "sentence = transcriptions[0][\"transcription\"]\n",
        "print(\"English: \" +sentence)\n",
        "\n",
        "print(\"Spanish: \" +decode(sentence))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQU_0aRGaMNX",
        "outputId": "45099b32-144d-4dae-a6a6-2021b90e8c35"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: i love you\n",
            "Spanish: [start] te amo [end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sD-3ceHXezzW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}